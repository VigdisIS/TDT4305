{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461633a",
   "metadata": {},
   "source": [
    "### Enter full names of group members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4648c5",
   "metadata": {},
   "source": [
    "##### Name A: Vigdis-Irene Steinsund\n",
    "##### Name B: Thomas Hasvold Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "30d55dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sympy import prime\n",
    "from pathlib import Path  # for paths of files\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class colors:\n",
    "    red = '\\033[91m'\n",
    "    green = '\\033[92m'\n",
    "    blue = '\\033[94m'\n",
    "    end = '\\033[0m'  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4a780",
   "metadata": {},
   "source": [
    "### 1. DGIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287695e",
   "metadata": {},
   "source": [
    "#### 1.1. DGIM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "2af55744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default DGIM parameters\n",
    "\n",
    "stream_path = 'data/my_stream.txt'\n",
    "\n",
    "# The window size\n",
    "N = 500 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "3f339cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgim_algorithm(stream_path, N):\n",
    "    # Create the buckets and initialize the timestamp\n",
    "    buckets = []\n",
    "    timestamp = 0\n",
    "\n",
    "    # Loop through the entire data stream, one bit at a time\n",
    "    with open(stream_path) as f:\n",
    "        while True:\n",
    "            bit = f.read(1)\n",
    "\n",
    "            # Clause to break while loop at the end of the stream\n",
    "            if not bit:\n",
    "                break\n",
    "\n",
    "            # Update the timestamp - timestamp is recorded as modulo N\n",
    "            timestamp = (timestamp + 1) % N\n",
    "\n",
    "            # Tuple should be (size, timestamp)\n",
    "            # If the bit is a '1', add new tuple to buckets with size = 1\n",
    "            # Then start looping over all buckets to check if any need merging\n",
    "            # If there are more than two tuples with the same size, merge them\n",
    "            if bit == '1':\n",
    "                new_bucket = (1, timestamp)\n",
    "                buckets.append(new_bucket)\n",
    "                for i in range(len(buckets)):\n",
    "                    try:\n",
    "                        # If there are three buckets with the same size, merge the first two\n",
    "                        if(buckets[i][0] == buckets[i+1][0] == buckets[i+2][0]):\n",
    "                            size = buckets[i][0]\n",
    "                            # Merge the two buckets - we get double the bits\n",
    "                            merged_size = size * 2 \n",
    "                            timestamp_to_keep = buckets[i+1][1]\n",
    "                            merged_tuple = (merged_size, timestamp_to_keep)\n",
    "                            # Replace the second bucket with the merged one\n",
    "                            buckets[i+1] = merged_tuple \n",
    "                            # Remove the first bucket\n",
    "                            buckets.pop(i) \n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            for bucket in buckets:\n",
    "                # drop the last (oldest) bucket if its end-time is prior to N time units before the current time.\n",
    "                if (timestamp - bucket[1]) % N >= N - 1:\n",
    "                    buckets.remove(bucket)\n",
    "\n",
    "    # Change to expected output format\n",
    "    # Current: [(size, ts), (size, ts), ...]\n",
    "    # Desired: List of timestamps for each size, so if there is only one '1' in the stream, the output should be [[ts]], and so on\n",
    "    buckets_final = []\n",
    "    ts_handled = []\n",
    "    for i in range(len(buckets)):\n",
    "        # If element is added, skip:\n",
    "        if buckets[i][1] in ts_handled:\n",
    "            continue\n",
    "        # If element is last in list and not already added, add it to its own list:\n",
    "        elif i == len(buckets)-1:\n",
    "            buckets_final.append([buckets[i][1]])\n",
    "            end_time_stamp = buckets[i][1]\n",
    "            break\n",
    "        # Check if the next element has the same size, if so add both to the same list\n",
    "        elif(buckets[i][0] == buckets[i+1][0]):\n",
    "            buckets_final.append([buckets[i][1], buckets[i+1][1]])\n",
    "            ts_handled.append(buckets[i+1][1])\n",
    "        else: # If ts not already added\n",
    "            buckets_final.append([buckets[i][1]])\n",
    "        \n",
    "        ts_handled.append(buckets[i][1])\n",
    "    \n",
    "    buckets = buckets_final[::-1]\n",
    "           \n",
    "    return buckets, end_time_stamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "6dc1d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = dgim_algorithm(stream_path, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "6966be95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of timestamps buckets from DGIM algorithm: \n",
      " [[99], [91, 96], [83, 89], [63, 75], [44], [6], [321, 446], [188]]\n",
      "The end timestamp: 99\n"
     ]
    }
   ],
   "source": [
    "print(f\"The updated list of timestamps buckets from DGIM algorithm: \\n {bucket[0]}\")\n",
    "print(f\"The end timestamp: {bucket[1]}\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c273257",
   "metadata": {},
   "source": [
    "#### 1.2. Query the Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "4cb0343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_count(stream_path, k):\n",
    "    stream_list = []\n",
    "    with open(stream_path, 'r') as file:\n",
    "        for line in file:\n",
    "            stream_list.extend(list(map(int, line.strip())))\n",
    "\n",
    "    # Convert the list into a numpy array\n",
    "    stream_array = np.array(stream_list)\n",
    "    \n",
    "    return int(np.sum(stream_array[-k:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "7f7f130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dgim_query(bucket, N, k):\n",
    "\n",
    "    # Extract the buckets and the end timestamp\n",
    "    bucket_list, end_time_stamp = bucket\n",
    "\n",
    "    # To estimate number of 1s in most recent k bits, we need to sum the sizes of the buckets (all but last) and add half the size of the last bucket.\n",
    "    # We know the sorted list is in format [[ts, ts], [ts], [ts,ts], ...] where the size of the bucket is 2^index.\n",
    "    # Therefore, first list in the bucket_list has size 2^0, second list has size 2^1, and so on.\n",
    "\n",
    "    # Initialize the count of 1s\n",
    "    one_count = 0\n",
    "\n",
    "    # Buckets used\n",
    "    buckets_used = []\n",
    "\n",
    "    # Iterate through the buckets\n",
    "    for bucket in bucket_list:\n",
    "        for timestamp in bucket:\n",
    "                # Check if timestamp falls within window\n",
    "                if (end_time_stamp - timestamp) % N < k:\n",
    "                    # If they do, add the size of the bucket to the count (from index which we know is 2^index)\n",
    "                    one_count+= 2**bucket_list.index(bucket)\n",
    "                    buckets_used.append(bucket)\n",
    "\n",
    "    # Get the index of the last bucket\n",
    "    last_bucket_index = bucket_list.index(buckets_used[-1])\n",
    "    # Subtract half the size of the last bucket from total count\n",
    "    one_count -= 2**(last_bucket_index)/2\n",
    "        \n",
    "    return math.ceil(one_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "387e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of queries\n",
    "K = [10, 50, 100, 300, 500] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "7702bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "The total 1s in the last 10 bits by DGIM: 4\n",
      "The true count of 1s in the last 10 bits: 5\n",
      "The DGIM error for predicted 1s in the last 10 bits:     20.0 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 50 bits by DGIM: 25\n",
      "The true count of 1s in the last 50 bits: 26\n",
      "The DGIM error for predicted 1s in the last 50 bits:     3.85 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 100 bits by DGIM: 61\n",
      "The true count of 1s in the last 100 bits: 51\n",
      "The DGIM error for predicted 1s in the last 100 bits:     19.61 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 300 bits by DGIM: 173\n",
      "The true count of 1s in the last 300 bits: 150\n",
      "The DGIM error for predicted 1s in the last 300 bits:     15.33 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 500 bits by DGIM: 269\n",
      "The true count of 1s in the last 500 bits: 241\n",
      "The DGIM error for predicted 1s in the last 500 bits:     11.62 %\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------\")\n",
    "for k in K:\n",
    "    dgim_count = dgim_query(bucket, 500, k)\n",
    "    true_count = actual_count(stream_path, k)\n",
    "    \n",
    "    print(f\"The total 1s in the last {k} bits by DGIM: {dgim_count}\")\n",
    "    print(f\"The true count of 1s in the last {k} bits: {true_count}\")\n",
    "    print(f\"The DGIM error for predicted 1s in the last {k} bits: \\\n",
    "    {round(abs(100*(dgim_count-true_count))/true_count,2)} %\")\n",
    "    print(\"---------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaceac",
   "metadata": {},
   "source": [
    "### 2. Bloom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "92883c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Username data for the creation of bloom filters - B\n",
    "data_file = (Path(\"data/bloom_username\").with_suffix('.csv'))\n",
    "\n",
    "# Test data to check the functionality and false positive rate\n",
    "test1_file = (Path(\"data/test1_username\").with_suffix('.csv'))\n",
    "test2_file = (Path(\"data/test2_username\").with_suffix('.csv'))\n",
    "\n",
    "# Default bloom filter parameters\n",
    "bloom_size = 1500000 # parameter N\n",
    "h = 3 # number of hash functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "6c5e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of bloom filter with zeros\n",
    "B = np.zeros(bloom_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "1c033746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 972,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73d660",
   "metadata": {},
   "source": [
    "#### 2.1. Create Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "75b69edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "def generate_hash(h, N):\n",
    "    hash_list = []\n",
    "\n",
    "    # Generate a list of hash functions\n",
    "    for i in range(h):\n",
    "        # Generate a random prime number p\n",
    "        p = sympy.randprime(2, 1000)\n",
    "        # The hash function computes the sum of the ASCII values of the characters in the string multiplied by p^i mod N\n",
    "        hash_function = lambda s, p=p, N=N: sum([ord(s[i]) * (p ** i) for i in range(len(s))]) % N\n",
    "        # Append the hash function to the list\n",
    "        hash_list.append(hash_function)\n",
    "    \n",
    "    return hash_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "a75aeecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = generate_hash(h, bloom_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "0d2d4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bloom_filter(B, hashes, data):\n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            \n",
    "            # Update the hash index of the bloom filter with 1s\n",
    "            for hash_function in hashes:\n",
    "                index = hash_function(name)\n",
    "                B[index] = 1\n",
    "            \n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "fe79b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_array = create_bloom_filter(B, hashes, data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "d7ce957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff48616",
   "metadata": {},
   "source": [
    "#### 2.2. Verify usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "530485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_verify_username(bloom_array, hashes, new_user):\n",
    "    \n",
    "    # Verify username and return a code of 0 or 1 (1 - username taken and 0 - username available)\n",
    "    for hash_function in hashes:\n",
    "        index = hash_function(new_user)\n",
    "        # Check if bit is set or not\n",
    "        if bloom_array[index] == 0:  \n",
    "            return 0\n",
    "    # If all bits are sets, username is likely already taken\n",
    "    return 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "b6edf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to test different usernames here\n",
    "\n",
    "new_username = \"KazeemTDT4305\"\n",
    "\n",
    "# new_username = \"ShambaTDT4305\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "22690d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = single_verify_username(bloom_array, hashes, new_username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "b7730361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mUsername KazeemTDT4305 is available. Congrats!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if user_code == 1:\n",
    "    print(colors.red + f\"Username {new_username} has been taken. Try again!\" + colors.end)\n",
    "elif user_code == 0:\n",
    "    print(colors.green + f\"Username {new_username} is available. Congrats!\" + colors.end)\n",
    "else:\n",
    "    print(colors.blue + f\"Wrong pass code. Please reverify!\" + colors.end)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "080d7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_verify_username(bloom_array, hashes, data):\n",
    "    # Initialize counts\n",
    "    total_name = 0\n",
    "    taken_name = 0\n",
    "    \n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            # Similar to the single verify, but returns a percentage of usernames taken...\n",
    "            # ...(In other words seen already by the bloom filter during its creation)\n",
    "            if single_verify_username(bloom_array, hashes, name) == 1:\n",
    "                taken_name += 1  # Username likely seen/taken\n",
    "            total_name += 1  # Increment total count regardless\n",
    "            \n",
    "    return round(taken_name/total_name*100,2)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "4725c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 1: 100.0%\n",
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 2: 23.81%\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test1_file)\n",
    "print(f\"Percentage of username seen before from test 1: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test2_file)\n",
    "print(f\"Percentage of username seen before from test 2: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488c00b",
   "metadata": {},
   "source": [
    "### 3. Flajolet-Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "dae74f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flajolet_martin(input_stream):\n",
    "    R = 0  # Initialize maximum rightmost zero bit position to 0\n",
    "\n",
    "    # Define hash function h(x) = 6x + 1 mod 5\n",
    "    hash_function = lambda x: (6*x + 1) % 5\n",
    "\n",
    "    # Iterate over the input stream - for each element we want to find the number of trailing zeroes in the binary representation of the hash value\n",
    "    for element in input_stream:\n",
    "        # Apply hash function\n",
    "        hash_value = hash_function(element)\n",
    "\n",
    "        # Convert to binary after applying hash function\n",
    "        binary_hash = bin(hash_value)[2:]\n",
    "\n",
    "        # Calculate number of trailing zeroes in the binary hash\n",
    "        trailing_zeroes = len(binary_hash) - len(binary_hash.rstrip('0'))\n",
    "\n",
    "        # If the current number of trailing zeroes is greater than the current maximum, update the maximum\n",
    "        R = max(R, trailing_zeroes)\n",
    "\n",
    "    # Estimate the number of distinct elements\n",
    "    distinct_estimate = 2 ** R\n",
    "\n",
    "    return distinct_estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "c7a283b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 1: 2\n",
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 2: 4\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Input stream\n",
    "input_stream1 = [1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
    "input_stream2 = [1, 3, 2, 1, 2, 3, 4, 3, 1, 2, 3, 1]\n",
    "\n",
    "# Run the Flajolet-Martin algorithm\n",
    "distinct_estimate1 = flajolet_martin(input_stream1)\n",
    "distinct_estimate2 = flajolet_martin(input_stream2)\n",
    "\n",
    "# Print the estimated number of distinct elements\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 1:\", distinct_estimate1)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 2:\", distinct_estimate2)\n",
    "print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3051ee5",
   "metadata": {},
   "source": [
    "### 4. Adword "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b08ba",
   "metadata": {},
   "source": [
    "#### 4.1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "a58d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User queries\n",
    "queries = [\"big data\", \"big data\", \"big data\",\"bloom filters\", \"bloom filters\", \"bloom filters\",\n",
    "           \"flajolet martin\", \"flajolet martin\", \"flajolet martin\", \"dgim algorithm\", \"dgim algorithm\", \"dgim algorithm\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "66ee11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company A B C and D keywords and budget $$$\n",
    "global_companies = {\n",
    "        'A': [\"big data\", \"bloom filters\", 3],\n",
    "        'B': [\"flajolet martin\", 3],\n",
    "        'C': [\"flajolet martin\", \"dgim algorithm\", 3],\n",
    "        'D': [\"big data\", 3],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "fd6eb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    \n",
    "    # To-do! update revenue using greedy algorithm\n",
    "    \n",
    "    return revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "7c9378f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Greedy Algorithm...\n",
      "------------------------------------------------\n",
      "Trial 1 - Revenue generated: 0\n",
      "Trial 2 - Revenue generated: 0\n",
      "Trial 3 - Revenue generated: 0\n",
      "Trial 4 - Revenue generated: 0\n",
      "Trial 5 - Revenue generated: 0\n",
      "Trial 6 - Revenue generated: 0\n",
      "Trial 7 - Revenue generated: 0\n",
      "Trial 8 - Revenue generated: 0\n",
      "Trial 9 - Revenue generated: 0\n",
      "Trial 10 - Revenue generated: 0\n",
      "------------------------------------------------\n",
      "Average revenue generated for all trials:  0.0\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Greedy Algorithm...\")\n",
    "print(\"------------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = greedy_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"------------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fda97",
   "metadata": {},
   "source": [
    "#### 4.2. Balance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "9af1b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    \n",
    "    # To-do! update revenue using balance algorithm\n",
    "    \n",
    "    return revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "8b975413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Balance Algorithm...\n",
      "-------------------------------------------\n",
      "Trial 1 - Revenue generated: 0\n",
      "Trial 2 - Revenue generated: 0\n",
      "Trial 3 - Revenue generated: 0\n",
      "Trial 4 - Revenue generated: 0\n",
      "Trial 5 - Revenue generated: 0\n",
      "Trial 6 - Revenue generated: 0\n",
      "Trial 7 - Revenue generated: 0\n",
      "Trial 8 - Revenue generated: 0\n",
      "Trial 9 - Revenue generated: 0\n",
      "Trial 10 - Revenue generated: 0\n",
      "-------------------------------------------\n",
      "Average revenue generated for all trials:  0.0\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Balance Algorithm...\")\n",
    "print(\"-------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = balance_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"-------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ef9e",
   "metadata": {},
   "source": [
    "### 5. Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "86174f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings matrix (each row corresponds to a movie, and each column corresponds to a user)\n",
    "ratings_matrix = np.array([\n",
    "    [1, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 0],\n",
    "    [0, 0, 5, 4, 0, 0, 4, 0, 0, 2, 1, 3],\n",
    "    [2, 4, 0, 1, 2, 0, 3, 0, 4, 3, 5, 0],\n",
    "    [0, 2, 4, 0, 5, 0, 0, 4, 0, 0, 2, 0],\n",
    "    [0, 0, 4, 3, 4, 2, 0, 0, 0, 0, 2, 5],\n",
    "    [1, 0, 3, 0, 3, 0, 0, 2, 0, 0, 4, 0]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92e8e0",
   "metadata": {},
   "source": [
    "#### 5.1. User-User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "0749438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a user-user CF using cosine similarity as distance measure\n",
    "    \n",
    "    return prediction   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "c153de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuple of movie rating by users to be predicted e.g (1, 5) refers to the rating of movie 1 by user 5\n",
    "list_mu_query = [(1, 5), (3, 3)]\n",
    "\n",
    "# Neighbor selection (|N|)\n",
    "neigh = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "22f8e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vigdissteinsund/uni/TDT4305/project_3/Project 3 - Mining Data Streams, Adwords and RecSys.ipynb Cell 49\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-----------------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)   \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m mu_query \u001b[39min\u001b[39;00m list_mu_query:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     predicted_rating \u001b[39m=\u001b[39m user_cf(ratings_matrix, mu_query, neigh)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe predicted rating of movie \u001b[39m\u001b[39m{\u001b[39;00mmu_query[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m by user \u001b[39m\u001b[39m{\u001b[39;00mmu_query[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mpredicted_rating\u001b[39m}\u001b[39;00m\u001b[39m (User-User CF)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-----------------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)   \n",
      "\u001b[1;32m/Users/vigdissteinsund/uni/TDT4305/project_3/Project 3 - Mining Data Streams, Adwords and RecSys.ipynb Cell 49\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muser_cf\u001b[39m(rate_m, tup_mu, neigh):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# To-do! implement a user-user CF using cosine similarity as distance measure\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vigdissteinsund/uni/TDT4305/project_3/Project%203%20-%20Mining%20Data%20Streams%2C%20Adwords%20and%20RecSys.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m prediction\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = user_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (User-User CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217e4ed",
   "metadata": {},
   "source": [
    "#### 5.2. Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a item-item CF using cosine similarity as distance measure\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = item_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (Item-Item CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892ce96",
   "metadata": {},
   "source": [
    "### Provide concise answers to all 5 cases in the Project 3 description below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc34aad",
   "metadata": {},
   "source": [
    "#### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b85a6",
   "metadata": {},
   "source": [
    "#### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8340d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16cad2",
   "metadata": {},
   "source": [
    "#### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9e628",
   "metadata": {},
   "source": [
    "#### Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c341065",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3aa9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter answer here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
